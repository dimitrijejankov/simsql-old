

/*****************************************************************************
 *                                                                           *
 *  Copyright 2014 Rice University                                           *
 *                                                                           *
 *  Licensed under the Apache License, Version 2.0 (the "License");          *
 *  you may not use this file except in compliance with the License.         *
 *  You may obtain a copy of the License at                                  *
 *                                                                           *
 *      http://www.apache.org/licenses/LICENSE-2.0                           *
 *                                                                           *
 *  Unless required by applicable law or agreed to in writing, software      *
 *  distributed under the License is distributed on an "AS IS" BASIS,        *
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. *
 *  See the License for the specific language governing permissions and      *
 *  limitations under the License.                                           *
 *                                                                           *
 *****************************************************************************/


package simsql.runtime;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.RawComparator;
import org.apache.hadoop.io.DataInputBuffer;
import org.apache.hadoop.util.Progress;
import org.apache.hadoop.mapred.RawKeyValueIterator;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.JobContext;
import org.apache.hadoop.mapreduce.ReduceContext;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.OutputCommitter;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.StatusReporter;
import org.apache.hadoop.mapreduce.TaskAttemptID;

import java.io.IOException;
import java.util.List;
import java.util.ArrayList;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;


public class FastReducer<K1, V1, K2, V2> extends Reducer<K1, V1, K2, V2> {
  
  private Context outer;
  private Pair MARKER = Pair.createPair(null, null);
  private Pair MARKERFORPRODUCER = Pair.createPair(null, null);
  private Pair MARKERFORCONSUMER = Pair.createPair(null, null);

  public class JContext extends Context {

    private final BlockingQueue queue;
    private BlockingQueue newqueue;
    private CollectionSizeEstimator CSEcon;
    private boolean first;

    public JContext(Configuration conf, TaskAttemptID taskid,
                    RawKeyValueIterator input, 
                    Counter inputKeyCounter,
                    Counter inputValueCounter,
                    RecordWriter<K2,V2> output,
                    OutputCommitter committer,
                    StatusReporter reporter,
                    RawComparator<K1> comparator,
                    Class<K1> keyClass,
                    Class<V1> valueClass,
                    BlockingQueue q) throws IOException, InterruptedException {
      super(conf, taskid, input, inputKeyCounter, inputValueCounter,
            output, committer, reporter, 
            comparator, keyClass, valueClass);
      queue = q;
      newqueue = null;
      CSEcon = new CollectionSizeEstimator(queue, 10*1024);
      first = true;
    }

    //a fake write() method
    @SuppressWarnings("unchecked")
    public void write(K2 key, V2 value) throws IOException, InterruptedException {
      Pair<K2, V2> pair = Pair.createPair(key, value);
      if(first && !CSEcon.haveCapacity()) {
        // System.err.println("Sorry I have no information!");
        queue.put(pair);
        CSEcon.updateEstimate();
      } else if(first) {
        // System.err.println("I got it! It's " + CSEcon.getCapacity());
        newqueue = new LinkedBlockingQueue<Pair<K2, V2>>(CSEcon.getCapacity());
        queue.drainTo(newqueue);
        newqueue.put(pair);
        first = false;
      } else {
        // System.err.println("I'm writing to the new queue!");        
        newqueue.put(pair);
      }
    }

    public BlockingQueue getBoundedQueue() {
      return newqueue;
    }

  }

  public static class Pair<K, V> {

    private final K element0;
    private final V element1;

    public static <K, V> Pair<K, V> createPair(K key, V value) {
      return new Pair<K, V>(key, value);
    }

    public Pair(K element0, V element1) {
      this.element0 = element0;
      this.element1 = element1;
    }

    public K getElement0() {
      return element0;
    }

    public V getElement1() {
      return element1;
    }

  }

  public class Producer implements Runnable {

    private final BlockingQueue queue;

    public Producer(BlockingQueue q) { 
      queue = q; 
    }

    @SuppressWarnings("unchecked")
    public void run() {
      try {
        while(outer.nextKey()) { 
          for (V1 value : outer.getValues()) {
            Pair<K1, V1> pair = Pair.createPair(outer.getCurrentKey(), value);
            queue.put(pair); 
          }
          queue.put(MARKER);
        }
        queue.put(MARKERFORPRODUCER);
      } catch (IOException ex) { 
        ex.printStackTrace();
      } catch (InterruptedException ex) { 
        ex.printStackTrace();
      } 
    }

  }

  public class Consumer implements Runnable {

    private final BlockingQueue queue;

    public Consumer(BlockingQueue q) { 
      queue = q; 
    }

    @SuppressWarnings("unchecked")
    public void run() {
      try {
        Pair<K2, V2> pair = (Pair<K2, V2>) queue.take(); 
        while(pair != MARKERFORCONSUMER) { 
          consume(pair); 
          pair = (Pair<K2, V2>) queue.take(); 
        }
      } catch (IOException ex) { 
        ex.printStackTrace();
      } catch (InterruptedException ex) { 
        ex.printStackTrace();
      } 
    }

    void consume(Pair<K2, V2> x) throws IOException, InterruptedException { 
      outer.write(x.getElement0(), x.getElement1());
    }
  }

  public class FakeKeyValueIterator implements RawKeyValueIterator {
    public DataInputBuffer getKey() throws IOException {
      return null;
    }
    public DataInputBuffer getValue() throws IOException {
      return null;
    }
    public boolean next() throws IOException {
      return false;
    }
    public void close() throws IOException {}
    public Progress getProgress() {
      return null;
    }
  }
  
  @SuppressWarnings("unchecked")
  public void run(Context context) throws IOException, InterruptedException {

    outer = context;
    setup(context);

    BlockingQueue<Pair<K1, V1>> qpro = new LinkedBlockingQueue<Pair<K1, V1>>();
    CollectionSizeEstimator CSEpro = new CollectionSizeEstimator(qpro, 10*1024);
    BlockingQueue<Pair<K2, V2>> qcon = new LinkedBlockingQueue<Pair<K2, V2>>();

    while(!CSEpro.haveCapacity() && context.nextKey()) {
      K1 key = context.getCurrentKey();
      List<V1> values = new ArrayList<V1>();
      for (V1 value : context.getValues()) {
        qpro.put(Pair.createPair(key, value)); 
        CSEpro.updateEstimate();
        values.add(value);
      }
      reduce(key, values, context);
    }

    if(CSEpro.haveCapacity()) {
      BlockingQueue<Pair<K1, V1>> q1 = new LinkedBlockingQueue<Pair<K1, V1>>(CSEpro.getCapacity());
      Producer p = new Producer(q1);
      new Thread(p).start();

      //main thread
      JContext jcontext = new JContext(context.getConfiguration(), context.getTaskAttemptID(), new FakeKeyValueIterator(), 
                                       null, null, null, null, null, null, (Class<K1>) context.getMapOutputKeyClass(), 
                                       (Class<V1>) context.getMapOutputValueClass(), qcon);
      Pair<K1, V1> pair = (Pair<K1, V1>) q1.take(); 
      Thread t = null;
      BlockingQueue<Pair<K2, V2>> q2 = null;
      boolean consumerCreated = false;
      K1 key = null;
      List<V1> values = new ArrayList<V1>();
      while(pair != MARKERFORPRODUCER) { 
        if(pair != MARKER) {
          key = pair.getElement0();
          values.add(pair.getElement1());
        } else {
          reduce(key, values, jcontext);
          values.clear();
          if (!consumerCreated && jcontext.getBoundedQueue() != null) {
            // System.out.println("I get q2!");
            q2 = jcontext.getBoundedQueue();
            Consumer c = new Consumer(q2);
            t = new Thread(c);
            t.start();
            consumerCreated = true;
          }
        }
        pair = (Pair<K1, V1>) q1.take(); 
      }

      if (!consumerCreated) {
          q2 = qcon;
          Consumer c = new Consumer(q2);
          t = new Thread(c);
          t.start();
      }

      q2.put(MARKERFORCONSUMER);
      t.join();
    }

    cleanup(context);

  }

}

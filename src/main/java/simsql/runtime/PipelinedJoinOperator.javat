

/*****************************************************************************
 *                                                                           *
 *  Copyright 2014 Rice University                                           *
 *                                                                           *
 *  Licensed under the Apache License, Version 2.0 (the "License");          *
 *  you may not use this file except in compliance with the License.         *
 *  You may obtain a copy of the License at                                  *
 *                                                                           *
 *      http://www.apache.org/licenses/LICENSE-2.0                           *
 *                                                                           *
 *  Unless required by applicable law or agreed to in writing, software      *
 *  distributed under the License is distributed on an "AS IS" BASIS,        *
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. *
 *  See the License for the specific language governing permissions and      *
 *  limitations under the License.                                           *
 *                                                                           *
 *****************************************************************************/



package simsql.runtime;

import java.io.IOException;
import java.util.*;
import java.nio.ByteBuffer;

// the way that all of this works is that a network of pipelined operators is created, and
// inserted into the mapper of a relational operation.  When a record comes off of disk, the
// mapper first attempts to add the record into the network... and records that come out
// the "top" of the network, or that are not accepted by the network, are then processed
// by the mapper of the relational operation.
//
// Each pipelined operator should have an associated "BlahInput" record type, where "Blah"
// is a paremater.  This type corresponds to the input to the pipelined operator.  That way,
// the operator can accept its input off of the disk if the operator is at the leaf of the
// network (the mapper that is executing the network will add "BlahInput.class" into the 
// list of class types that can come off of disk).

// RIGHT is the larger, LEFT is the smaller

// in case we want to read the input records off of the disk, they can be read using this class
class <<<<pipeName>>>>Input extends AbstractRecord {

    public int getNumAttributes () {
      return <<<<rightNumAtts>>>>;
    }

    public short getTypeCode () {
      return <<<<rightTypeCode>>>>;
    }

    public <<<<pipeName>>>>Input () {}
}

// by definition, "LeftIn" should be the smaller of the two relations
class <<<<pipeName>>>> extends PipelinedOperator {

  private static final RecordPool jpool_res = new RecordPool(8192, new <<<<pipeName>>>>.Result());
  
  class LeftIn extends InputRecord {
  
    <<<<functionDeclarations>>>>

    public int getNumAttributes () {
      return <<<<leftNumAtts>>>>;
    }

    public short getTypeCode () {
      return <<<<leftTypeCode>>>>;
    }
 
    public HashableRecord runSelectionAndProjection () {

      Bitstring predResult = isPresent.and (<<<<leftSelection>>>>);
    
      // if we got nothing back, then return a nul
      if (predResult.allAreFalseOrUnknown ()) {
        return null;
      }    
    
      HashableRecord returnVal = new LeftOut ();
//      returnVal.atts = new Attribute [returnVal.getNumAttributes ()];

      returnVal.setSortAttribute(getSortAttribute());

      <<<<leftAssignments>>>>
      returnVal.isPresent = predResult;

      return returnVal;
    }
  
    public LeftIn () {}
  
  }

/* LL note: I've changed this input record class to economize
   memory. In reality, it is not necessary to keep more than one
   instance of RightIn and RightOut per *pipelined* join operator. In
   process(), RightIn is always read from the input record, and a
   single instance of RightOut is created, passed to join() and then
   discarded.

   Note that (so far) this applies only to this particular operator.

*/

  class RightIn extends InputRecord {

    <<<<functionDeclarations>>>>

    public int getNumAttributes () {
      return <<<<rightNumAtts>>>>;
    }

    public short getTypeCode () {
      return <<<<rightTypeCode>>>>;
    }

    // our output record.
    private HashableRecord returnVal;
 
    public HashableRecord runSelectionAndProjection () {

      Bitstring predResult = isPresent.and (<<<<rightSelection>>>>);
    
      // if we got nothing back, then return a nul
      if (predResult.allAreFalseOrUnknown ()) {
        return null;
      }    
      
      <<<<rightAssignments>>>>
      returnVal.isPresent = predResult;
      returnVal.setSortAttribute(getSortAttribute());

      return returnVal;
    }
  
    // here we make that single instance...
    public RightIn () {
      returnVal = new RightOut();
//      returnVal.atts = new Attribute [returnVal.getNumAttributes()];
    }
  }

  private static int[] _split_atts_left = new int[]{<<<<leftHashPositions>>>>};

  class LeftOut extends HashableRecord {

    private int[] _split_atts = _split_atts_left;

    <<<<functionDeclarations>>>>
  
    public int getNumAttributes () {
      return <<<<leftNumOutAtts>>>>; 
    }
  
    public long getHashKey () {
      return ((long) 0) <<<<leftHash>>>>; 
    }
    
    public short getTypeCode () {
      return 2929;  
    }

    @Override
    public HashableRecord[] splitSome() {
      return split(_split_atts);
    }
  
    public LeftOut () {}
  
  }

  private static int [] _split_atts_right = new int[]{<<<<rightHashPositions>>>>};

  class RightOut extends HashableRecord {

    private int[] _split_atts = _split_atts_right;

    <<<<functionDeclarations>>>>
  
    public int getNumAttributes () {
      return <<<<rightNumOutAtts>>>>; 
    }
  
    public long getHashKey () {
      return ((long) 0) <<<<rightHash>>>>; 
    }
  
    public short getTypeCode () {
      return 3232;  
    }
  
    @Override
    public HashableRecord[] splitSome() {
      return split(_split_atts);
    }  

    @Override
    public Record buildRecordOfSameType () {
        return new RightOut ();
    }

    public RightOut () {}
  }

  public static class Result extends AbstractRecord {

    <<<<functionDeclarations>>>>    
  
    public int getNumAttributes () {
      return <<<<outputNumOutAtts>>>>; 
    }

    public Result () {}
    
    // join two records; return null if they don't match; return the resulting
    // Record object otherwise
    public Record join (AbstractRecord left, AbstractRecord right) {

      // make sure that we have the records in the correct order...
      // if this is not the case, then swap them
      if (<<<<swappedLeftAndRight>>>>) {
        AbstractRecord temp = left;
        left = right;
        right = temp;
      }
    
      // check the join predicate
      Bitstring predResult = <<<<outputSelection>>>>.and (left.isPresent).and (right.isPresent); 
    
      // if we got nothing back, then return a nul
      if (predResult.allAreFalseOrUnknown ()) {
        return null;
      }
    
      Result output = (Result)jpool_res.get();

      output.isPresent = predResult;
      <<<<outputAssignments>>>>
      return output;
    }
  
    public short getTypeCode () {
      return <<<<outputTypeCode>>>>;  
    }
  }

  // the hash table
  RecordHashTable myHashTable;

  // set up the pipeline
  public <<<<pipeName>>>> () {
     // for efficiency, we don't set up anything here... we set up when we see the first record 
  }

  // this sets up the hash table 
  private void getReady () {

    String smallRelation = "<<<<smallRelName>>>>";

    IteratorFactory myFactory = new IteratorFactory ();
    myHashTable = new RecordHashTable (0.6);

    // now, hash all of the records in the small guy
    LeftIn tempRec = new LeftIn ();
    for (Record r : myFactory.getIterableForFile (smallRelation, tempRec.getNumAttributes (), tempRec.getTypeCode ())) {
     
      // load the record into the hash table
      tempRec.copyMyselfFrom (r);
      HashableRecord writeMe = tempRec.runSelectionAndProjection ();

      // keep going if we got nothing
      if (writeMe == null)
        continue;

      // split on the join attributes
      HashableRecord[] splits = writeMe.splitSome();
      for (HashableRecord rec: splits) {
        myHashTable.add (rec, rec.getHashKey ());
      }
    }
  }

  // this returns true if the pipe accepts records of this type
  public boolean accepts (Record value) {
    return value.getTypeCode () == <<<<rightTypeCode>>>>; 
  }

  // so we can call Result.join
  Result dummy = new Result ();

  // for the output.
  RightIn input = new RightIn ();

  // process the record by sending it through the pipe
  public void process (Record value) {

    // if we have not been set up, then do so
    if (myHashTable == null)
      getReady ();
    
    // first, cast "value" to the InputRecord type
    try {
      input.copyMyselfFrom (value);
    } catch (Exception e) {
      throw new RuntimeException ("For some reason, the cast of the input record in the mapper failed!"); 
    }

    // run the selection and projection
    HashableRecord writeMe = input.runSelectionAndProjection ();
    
    // if we got nothing back, the record was killed by the selection
    if (writeMe == null) {
      return;  
    }

    // try to join it... first, split on the join attributes
    HashableRecord [] splits = writeMe.splitSome();
    for (HashableRecord rec: splits) {

      // get the hash key
      long hashKey = rec.getHashKey ();
      Record [] result = myHashTable.find (hashKey);	

      if (result == null)
        continue;

      // now, try to join all of the results
      for (Record r : result) {
        Record output = dummy.join ((AbstractRecord) r, rec);
        if (output != null) {
          if (input.hasSortAttribute ())
            output.setSortAttribute (input.getSortAttribute ());
          emit (output);
        }
      }
    }

  }
}



